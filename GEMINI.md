# Gemini-CLI ZAI Fork

Fork of gemini-cli adapted to use ZAI's GLM-4.7 API for benchmarking.

## Objectives

1. Implement ZAI with thinking capabilities (GLM-4.7)
2. Add mode to disable thinking
3. Connect web search to ZAI's API

---

## ZAI API Reference (Verified by Testing)

### Endpoints

| Endpoint                                               | Purpose                             | Notes                                  |
| ------------------------------------------------------ | ----------------------------------- | -------------------------------------- |
| `https://api.z.ai/api/coding/paas/v4/chat/completions` | **Coding Plan** (used in this fork) | Preserved Thinking enabled by default  |
| `https://api.z.ai/api/paas/v4/chat/completions`        | Standard API                        | Preserved Thinking disabled by default |

### Authentication

```
Authorization: Bearer $ZAI_API_KEY
```

### Thinking Configuration

```json
{
  "thinking": {
    "type": "enabled", // "enabled" | "disabled"
    "clear_thinking": false // false = Preserved Thinking (keep reasoning in context)
  }
}
```

**Key Points:**

- `type: "enabled"` (default for GLM-4.7): Model reasons before answering,
  returns `reasoning_content`
- `type: "disabled"`: Direct answers, no reasoning, faster/cheaper (~2 tokens vs
  ~70+ for same question)
- `clear_thinking: false`: Preserve reasoning across turns (better for
  multi-turn coding sessions)
- `clear_thinking: true`: Clear reasoning each turn (saves tokens but loses
  context)

**Turn-level Thinking** (GLM-4.7): You can toggle `thinking.type` on each
request within the same session:

- Enable for complex planning, debugging, multi-constraint reasoning
- Disable for quick tool execution, simple facts, formatting requests

**Critical Preserved Thinking Constraint:**

> All consecutive `reasoning_content` blocks must **exactly match the original
> sequence** generated by the model. Do not reorder or edit these blocks;
> otherwise, performance degrades and cache hit rates drop.

### Response Structure

```json
{
  "choices": [{
    "message": {
      "content": "Final answer",
      "reasoning_content": "Thinking process...",  // Only if thinking enabled
      "role": "assistant",
      "tool_calls": [...]  // If tools requested
    },
    "finish_reason": "stop"
  }],
  "usage": {
    "prompt_tokens": 17,
    "completion_tokens": 72,
    "total_tokens": 89,
    "prompt_tokens_details": {"cached_tokens": 2},         // Preserved Thinking cache hits
    "completion_tokens_details": {"reasoning_tokens": 69}  // Tokens spent on thinking
  }
}
```

### Streaming (SSE)

Request with `"stream": true`. Response format:

```
data: {"choices":[{"delta":{"reasoning_content":"..."}}]}
data: {"choices":[{"delta":{"content":"..."}}]}
data: {"choices":[{"finish_reason":"stop"}],"usage":{...}}
data: [DONE]
```

### Tool Calling

Standard OpenAI-compatible format:

```json
{
  "tools": [{
    "type": "function",
    "function": {
      "name": "tool_name",
      "description": "...",
      "parameters": {"type": "object", "properties": {...}}
    }
  }],
  "tool_choice": "auto"  // "auto" | "none" | "required" | {"type":"function","function":{"name":"..."}}
}
```

**Interleaved Thinking Flow** (tool calls with reasoning):

```
1. User message
2. Assistant reasons (reasoning_content) → decides to call tool
3. Tool executes, returns result
4. Assistant reasons about result (reasoning_content) → final answer or more tools
```

**Preserving reasoning across tool calls** - Include full `reasoning_content` in
message history:

```json
// After assistant response with tool call:
{"role": "assistant", "content": "", "reasoning_content": "I need to check...", "tool_calls": [{"id": "call_1", "type": "function", "function": {"name": "get_weather", "arguments": "{\"city\":\"Paris\"}"}}]}

// After tool result:
{"role": "tool", "tool_call_id": "call_1", "content": "{\"temp\": \"22°C\"}"}

// Next request - model continues reasoning from preserved context
```

### Web Search

**Option 1: Web Search in Chat** (LLM processes search results)

```json
{
  "tools": [
    {
      "type": "web_search",
      "web_search": {
        "enable": "True",
        "search_engine": "search-prime",
        "count": "5",
        "search_domain_filter": "example.com", // Optional: restrict to domain
        "search_recency_filter": "noLimit", // Optional: "day", "week", "month", "year", "noLimit"
        "search_result": "True", // Return raw search results in response
        "search_prompt": "Summarize key points from {{search_result}}", // Optional: custom processing
        "content_size": "high" // Summary length: "low", "medium", "high"
      }
    }
  ]
}
```

Response includes both LLM answer and raw search results:

```json
{
  "choices": [{ "message": { "content": "Based on search results..." } }],
  "web_search": [
    {
      "title": "...",
      "link": "https://...",
      "content": "...",
      "media": "Site Name",
      "refer": "ref_1"
    }
  ]
}
```

**Option 2: Standalone Web Search API** (raw results only, no LLM)

```
POST https://api.z.ai/api/paas/v4/web_search
{
  "search_engine": "search-prime",
  "search_query": "your query",
  "count": 10
}
```

> Note: Requires separate billing. Coding endpoint includes web search in chat
> for free.

**Option 3: MCP Server** (for Cursor, Claude Code, etc.)

```json
{
  "mcpServers": {
    "z.ai-web-search": {
      "url": "https://api.z.ai/api/mcp/web_search/sse?Authorization=YOUR_API_KEY"
    }
  }
}
```
# Gemini CLI Project Context

Gemini CLI is an open-source AI agent that brings the power of Gemini directly
into the terminal. It is designed to be a terminal-first, extensible, and
powerful tool for developers.

## Project Overview

- **Purpose:** Provide a seamless terminal interface for Gemini models,
  supporting code understanding, generation, automation, and integration via MCP
  (Model Context Protocol).
- **Main Technologies:**
  - **Runtime:** Node.js (>=20.0.0, recommended ~20.19.0 for development)
  - **Language:** TypeScript
  - **UI Framework:** React (using [Ink](https://github.com/vadimdemedes/ink)
    for CLI rendering)
  - **Testing:** Vitest
  - **Bundling:** esbuild
  - **Linting/Formatting:** ESLint, Prettier
- **Architecture:** Monorepo structure using npm workspaces.
  - `packages/cli`: User-facing terminal UI, input processing, and display
    rendering.
  - `packages/core`: Backend logic, Gemini API orchestration, prompt
    construction, and tool execution.
  - `packages/core/src/tools/`: Built-in tools for file system, shell, and web
    operations.
  - `packages/a2a-server`: Experimental Agent-to-Agent server.
  - `packages/vscode-ide-companion`: VS Code extension pairing with the CLI.

## Building and Running

- **Install Dependencies:** `npm install`
- **Build All:** `npm run build:all` (Builds packages, sandbox, and VS Code
  companion)
- **Build Packages:** `npm run build`
- **Run in Development:** `npm run start`
- **Run in Debug Mode:** `npm run debug` (Enables Node.js inspector)
- **Bundle Project:** `npm run bundle`
- **Clean Artifacts:** `npm run clean`

## Testing and Quality

- **Test Commands:**
  - **Unit (All):** `npm run test`
  - **Integration (E2E):** `npm run test:e2e`
  - **Workspace-Specific:** `npm test -w <pkg> -- <path>` (Note: `<path>` must
    be relative to the workspace root, e.g.,
    `-w @google/gemini-cli-core -- src/routing/modelRouterService.test.ts`)
- **Full Validation:** `npm run preflight` (Heaviest check; runs clean, install,
  build, lint, type check, and tests. Recommended before submitting PRs.)
- **Individual Checks:** `npm run lint` / `npm run format` / `npm run typecheck`

## Development Conventions

- **Contributions:** Follow the process outlined in `CONTRIBUTING.md`. Requires
  signing the Google CLA.
- **Pull Requests:** Keep PRs small, focused, and linked to an existing issue.
- **Commit Messages:** Follow the
  [Conventional Commits](https://www.conventionalcommits.org/) standard.
- **Coding Style:** Adhere to existing patterns in `packages/cli` (React/Ink)
  and `packages/core` (Backend logic).
- **Imports:** Use specific imports and avoid restricted relative imports
  between packages (enforced by ESLint).

## Testing Conventions

- **Environment Variables:** When testing code that depends on environment
  variables, use `vi.stubEnv('NAME', 'value')` in `beforeEach` and
  `vi.unstubAllEnvs()` in `afterEach`. Avoid modifying `process.env` directly as
  it can lead to test leakage and is less reliable. To "unset" a variable, use
  an empty string `vi.stubEnv('NAME', '')`.

## Documentation

- Always use the `docs-writer` skill when you are asked to write, edit, or
  review any documentation.
- Documentation is located in the `docs/` directory.
- Suggest documentation updates when code changes render existing documentation
  obsolete or incomplete.